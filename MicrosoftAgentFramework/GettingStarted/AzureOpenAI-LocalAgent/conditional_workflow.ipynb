{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d2b849",
   "metadata": {},
   "source": [
    "### Conditional Workflow with Microsoft Agent Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5641008",
   "metadata": {},
   "source": [
    "![conditional_workflow](./images/conditional_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agent-framework==1.0.0b251001 python-dotenv azure-ai-projects==1.1.0b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26dc221",
   "metadata": {},
   "source": [
    "### Import Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Literal\n",
    "from uuid import uuid4\n",
    "\n",
    "from typing_extensions import Never\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    executor,\n",
    "    Case,\n",
    "    Default,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8f8ab",
   "metadata": {},
   "source": [
    "### Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a37d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"API Key: {api_key}\")\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"Deployment Name: {deployment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f8585c",
   "metadata": {},
   "source": [
    "### Creating AzureOpenAIChatClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Creating the AzureOpenAIChatClient\n",
    "client = AzureOpenAIChatClient(\n",
    "    api_key = api_key,\n",
    "    endpoint = endpoint,\n",
    "    deployment_name = deployment_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8321d3b",
   "metadata": {},
   "source": [
    "### Defining the Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class RoutingResult(BaseModel):\n",
    "    is_technical_question: bool\n",
    "    original_question: str\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6483f5",
   "metadata": {},
   "source": [
    "### Creating Router Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b855de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the system prompt for the Router Agent\n",
    "system_prompt_router_agent = \"\"\"\n",
    "You are the Interview Router Agent.\n",
    "\n",
    "Your task:\n",
    "1. Read the user’s question carefully.\n",
    "2. Decide whether it belongs to:\n",
    "   - \"CodingAgent\" → if it involves technical topics such as programming, data structures, algorithms, time complexity, debugging, or software design.\n",
    "   - \"BehavioralAgent\" → if it involves personality, teamwork, motivation, HR, or experience-based questions.\n",
    "\n",
    "Examples:\n",
    "Q: \"Explain quicksort.\" → coding\n",
    "Q: \"Tell me about a time you handled conflict.\" → behavioral\n",
    "Q: \"How would you optimize an algorithm?\" → coding\n",
    "Q: \"What motivates you?\" → behavioral\n",
    "\n",
    "Output Instructions:\n",
    "Always return JSON with fields `is_technical_question` set to true or false and `original_question` containing the user's question.\n",
    "\"\"\"\n",
    "\n",
    "# Creating the Router Agent\n",
    "router_agent = AgentExecutor(client.create_agent(\n",
    "    instructions = system_prompt_router_agent,\n",
    "    response_format = RoutingResult,\n",
    "),\n",
    "    id = \"RouterAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f0c8e",
   "metadata": {},
   "source": [
    "### Creating the Coding Agent (The Technical Interviewer Coach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50527b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the system prompt for the Coding Agent (The Technical Interviewer Coach)\n",
    "system_prompt_coding_agent = \"\"\"\n",
    "You are the Coding Interview Coach Agent.\n",
    "\n",
    "Your job is to help users understand and solve programming and algorithmic interview questions.\n",
    "\n",
    "Guidelines:\n",
    "- Explain concepts clearly and step-by-step.\n",
    "- When appropriate, include small, readable code examples in Python.\n",
    "- Mention time and space complexity.\n",
    "- Use simple language — imagine you are teaching a student preparing for FAANG interviews.\n",
    "- End your response with one practical takeaway (e.g., “Try implementing this recursively and iteratively.”).\n",
    "\n",
    "Tone:\n",
    "- Friendly, confident, and encouraging — like a mentor.\n",
    "\n",
    "Examples:\n",
    "Q: \"What is binary search?\"\n",
    "A: Binary search is a divide-and-conquer algorithm that runs in O(log n) time...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Creating the Coding Agent (The Technical Interviewer Coach)\n",
    "coding_agent = AgentExecutor(client.create_agent(\n",
    "    instructions = system_prompt_coding_agent,\n",
    "    response_format = AgentResponse,\n",
    "),\n",
    "    id = \"CodingAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d0ca1",
   "metadata": {},
   "source": [
    "### Creating the Behavioral Agent (The HR Interviewer Coach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2344200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the system prompt for the Behavioral Agent (The HR Interviewer Coach)\n",
    "system_prompt_behavioral_agent = \"\"\"\n",
    "You are the Behavioral Interview Coach Agent.\n",
    "\n",
    "Your role is to help users prepare for behavioral or HR interview questions using the STAR method.\n",
    "\n",
    "Guidelines:\n",
    "- Always structure responses using the STAR framework:\n",
    "  **Situation:** Describe the context.\n",
    "  **Task:** What was expected of you?\n",
    "  **Action:** What you did.\n",
    "  **Result:** The measurable or emotional outcome.\n",
    "- Keep answers concise and positive.\n",
    "- Use professional but conversational tone.\n",
    "- If the question is vague, help the user brainstorm a suitable story.\n",
    "- End with one improvement tip (e.g., “Quantify your impact to make the story stronger.”).\n",
    "\n",
    "Examples:\n",
    "Q: \"Tell me about a time you led a team.\"\n",
    "A:\n",
    "**Situation:** During my college robotics project...\n",
    "**Task:** I was responsible for coordinating the design and programming...\n",
    "**Action:** I divided tasks, set up weekly check-ins, and helped resolve conflicts.\n",
    "**Result:** We won 2nd place at the national robotics competition.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Creating the Behavioral Agent (The HR Interviewer Coach)\n",
    "behavioral_agent = AgentExecutor(client.create_agent(\n",
    "    instructions = system_prompt_behavioral_agent,\n",
    "    response_format = AgentResponse\n",
    "),\n",
    "    id = \"BehavioralAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4223b6e",
   "metadata": {},
   "source": [
    "### Creating the Condition Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd58425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_agent_routing(expected_result: bool):\n",
    "\n",
    "    # The returned function will be used as an edge predicate.\n",
    "    # It receives whatever the upstream executor produced.\n",
    "    def condition(message: Any) -> bool:\n",
    "        try:\n",
    "            routing_result = RoutingResult.model_validate_json(message.agent_run_response.text)\n",
    "\n",
    "            # returns true if the expected routing result is that it is a technical question\n",
    "            # if its not a technical question, it returns false - which means it should go to the behavioral agent\n",
    "            return routing_result.is_technical_question == expected_result\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    return condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5ad67",
   "metadata": {},
   "source": [
    "### Creating Handler Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@executor\n",
    "async def forward_request_to_coding_agent(\n",
    "    response: AgentExecutorResponse,\n",
    "    ctx: WorkflowContext[AgentExecutorRequest]\n",
    ") -> None:\n",
    "    # Parse the routing result from the Router Agent's response and extract the original question\n",
    "    # the original question is then set as the input to the next agent (either coding or behavioral)\n",
    "    routing_result = RoutingResult.model_validate_json(response.agent_run_response.text)\n",
    "\n",
    "    request = AgentExecutorRequest(\n",
    "        messages = [ChatMessage(\n",
    "            Role.USER, text=routing_result.original_question)],\n",
    "            should_respond=True\n",
    "    )\n",
    "\n",
    "    await ctx.send_message(request)\n",
    "\n",
    "@executor\n",
    "async def forward_request_to_behavioral_agent(\n",
    "    response: AgentExecutorResponse,\n",
    "    ctx: WorkflowContext[AgentExecutorRequest]\n",
    ") -> None:\n",
    "    # Parse the routing result from the Router Agent's response and extract the original question\n",
    "    # the original question is then set as the input to the next agent (either coding or behavioral)\n",
    "    routing_result = RoutingResult.model_validate_json(response.agent_run_response.text)\n",
    "\n",
    "    request = AgentExecutorRequest(\n",
    "        messages = [ChatMessage(\n",
    "            Role.USER, text=routing_result.original_question)],\n",
    "            should_respond=True\n",
    "    )\n",
    "\n",
    "    await ctx.send_message(request)\n",
    "\n",
    "@executor\n",
    "async def handle_agent_response(\n",
    "    response: AgentExecutorResponse,\n",
    "    ctx: WorkflowContext[AgentExecutorRequest]\n",
    ") -> None:\n",
    "    agent_response = AgentResponse.model_validate_json(response.agent_run_response.text)\n",
    "    await ctx.yield_output(\"final agent answer: \\n\" + agent_response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5ec92",
   "metadata": {},
   "source": [
    "### Build the Conditional Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(router_agent)\n",
    "\n",
    "    # Route to coding path\n",
    "    .add_edge(router_agent, forward_request_to_coding_agent, condition=decide_agent_routing(True))\n",
    "    .add_edge(forward_request_to_coding_agent, coding_agent)\n",
    "    .add_edge(coding_agent, handle_agent_response)\n",
    "\n",
    "    # Route to behavioral path\n",
    "    .add_edge(router_agent, forward_request_to_behavioral_agent, condition=decide_agent_routing(False))\n",
    "    .add_edge(forward_request_to_behavioral_agent, behavioral_agent)\n",
    "    .add_edge(behavioral_agent, handle_agent_response)\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484e5e0",
   "metadata": {},
   "source": [
    "### Visualizing the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowBuilder, WorkflowViz\n",
    "\n",
    "viz = WorkflowViz(workflow)\n",
    "mermaid_content = viz.to_mermaid()\n",
    "\n",
    "# printing mermaid content as markdown\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_content}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b7109",
   "metadata": {},
   "source": [
    "### Executing the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentionaly using a technical question to see if the workflow routes it correctly to the Coding Agent\n",
    "request = AgentExecutorRequest(\n",
    "    messages = [ChatMessage(\n",
    "        Role.USER, text=\"Can you explain the concept of polymorphism in object-oriented programming?\")],\n",
    "    should_respond=True\n",
    ")\n",
    "events = await workflow.run(request)\n",
    "outputs = events.get_outputs()\n",
    "if outputs:\n",
    "    print(outputs[0])\n",
    "else:\n",
    "    print(\"No output received from the workflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentionaly using a behavioral question to see if the workflow routes it correctly to the Behavioral Agent\n",
    "request = AgentExecutorRequest(\n",
    "    messages = [ChatMessage(\n",
    "        Role.USER, text=\"Can you tell me about a time you faced a conflict at work and how you handled it?\")],\n",
    "    should_respond=True\n",
    ")\n",
    "events = await workflow.run(request)\n",
    "outputs = events.get_outputs()\n",
    "if outputs:\n",
    "    print(outputs[0])\n",
    "else:\n",
    "    print(\"No output received from the workflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = AgentExecutorRequest(\n",
    "    messages=[ChatMessage(Role.USER, text=\"Explain polymorphism\")],\n",
    "    should_respond=True\n",
    ")\n",
    "\n",
    "events = await workflow.run(request)\n",
    "outputs = events.get_outputs()\n",
    "\n",
    "if outputs:\n",
    "    print(\"Workflow Output:\", outputs[0])\n",
    "else:\n",
    "    print(\"No output received.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
