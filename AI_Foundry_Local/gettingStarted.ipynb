{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c36ba1",
   "metadata": {},
   "source": [
    "## Running LLMs Locally with Azure AI Foundry Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79949ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting foundry-local-sdk\n",
      "  Downloading foundry_local_sdk-0.3.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from foundry-local-sdk) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from foundry-local-sdk) (2.11.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from foundry-local-sdk) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.0.0->foundry-local-sdk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.0.0->foundry-local-sdk) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.0.0->foundry-local-sdk) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.0.0->foundry-local-sdk) (0.4.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->foundry-local-sdk) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->foundry-local-sdk) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->foundry-local-sdk) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->foundry-local-sdk) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx->foundry-local-sdk) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx->foundry-local-sdk) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->foundry-local-sdk) (0.4.6)\n",
      "Downloading foundry_local_sdk-0.3.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: foundry-local-sdk\n",
      "Successfully installed foundry-local-sdk-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install foundry-local-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c08fe1",
   "metadata": {},
   "source": [
    "### Use OpenAI SDK with Foundry Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08beb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The golden ratio, often denoted by the Greek letter phi (φ), is an irrational number approximately equal to 1.618033988749895. It arises when a line is divided into two parts such that the ratio of the whole line to the larger part is the same as the ratio of the larger part to the smaller part. Mathematically, if a line segment is divided into parts a and b with a being the longer part and b being the shorter part, then the golden ratio is achieved when (a+b)/a = a/b.\n",
      "\n",
      "\n",
      "The golden ratio is found in various aspects of art, architecture, and nature, often associated with aesthetically pleasing proportions. It has been used by artists and architects for centuries, notably in the works of Leonardo da Vinci and the Parthenon in Athens.\n",
      "\n",
      "\n",
      "The golden ratio can be expressed algebraically\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "# By using an alias, the most suitable model will be downloaded \n",
    "# to your end-user's device. \n",
    "alias = \"phi-3.5-mini\"\n",
    "\n",
    "# Create a FoundryLocalManager instance. This will start the Foundry\n",
    "# Local service if it is not already running and load the specified model.\n",
    "manager = FoundryLocalManager(alias)\n",
    "\n",
    "# The remaining code uses the OpenAI Python SDK to interact with the local model.\n",
    "# Configure the client to use the local Foundry service\n",
    "client = openai.OpenAI(\n",
    "    base_url=manager.endpoint,\n",
    "    api_key=manager.api_key  # API key is not required for local usage\n",
    ")\n",
    "\n",
    "# Set the model to use and generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=manager.get_model_info(alias).id,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the golden ratio?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c16850",
   "metadata": {},
   "source": [
    "### Streaming Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8f5fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The golden ratio, often denoted by the Greek letter phi (φ), is an irrational number approximately equal to 1.618033988749895. It arises when a line is divided into two parts such that the ratio of the whole line to the larger part is the same as the ratio of the larger part to the smaller part. Mathematically, if a line segment is divided into parts a and b with a being the longer part and b being the shorter part, then the golden ratio is achieved when (a+b)/a = a/b.\n",
      "\n",
      "\n",
      "The golden ratio is found in various aspects of art, architecture, and nature, often associated with aesthetically pleasing proportions. It has been used by artists and architects for centuries, notably in the works of Leonardo da Vinci and the Parthenon in Athens.\n",
      "\n",
      "\n",
      "The golden ratio can be expressed algebraically"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "# By using an alias, the most suitable model will be downloaded \n",
    "# to your end-user's device.\n",
    "alias = \"phi-3.5-mini\"\n",
    "\n",
    "# Create a FoundryLocalManager instance. This will start the Foundry \n",
    "# Local service if it is not already running and load the specified model.\n",
    "manager = FoundryLocalManager(alias)\n",
    "\n",
    "# The remaining code us es the OpenAI Python SDK to interact with the local model.\n",
    "\n",
    "# Configure the client to use the local Foundry service\n",
    "client = openai.OpenAI(\n",
    "    base_url=manager.endpoint,\n",
    "    api_key=manager.api_key  # API key is not required for local usage\n",
    ")\n",
    "\n",
    "# Set the model to use and generate a streaming response\n",
    "stream = client.chat.completions.create(\n",
    "    model=manager.get_model_info(alias).id,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the golden ratio?\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Print the streaming response\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb688516",
   "metadata": {},
   "source": [
    "### Using Requests Python Library with Foundry Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install with: pip install requests\n",
    "import requests\n",
    "import json\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "# By using an alias, the most suitable model will be downloaded \n",
    "# to your end-user's device. \n",
    "alias = \"phi-3.5-mini\"\n",
    "\n",
    "# Create a FoundryLocalManager instance. This will start the Foundry\n",
    "# Local service if it is not already running and load the specified model.\n",
    "manager = FoundryLocalManager(alias)\n",
    "\n",
    "url = manager.endpoint + \"/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": manager.get_model_info(alias).id,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the golden ratio?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
